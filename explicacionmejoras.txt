

Hola! Aqu√≠ te detallo los cambios principales que he realizado en tus archivos para cumplir con todos tus requisitos.

1. Mejoras en app_mejorada.py (La Aplicaci√≥n Streamlit)

Tu archivo app111.py era una aplicaci√≥n de una sola p√°gina. La he transformado en una aplicaci√≥n web multi-p√°gina mucho m√°s robusta y profesional.

Estructura Multi-P√°gina

He usado el sistema de navegaci√≥n de Streamlit para crear un men√∫ lateral. Ahora la aplicaci√≥n tiene varias secciones claras:

Inicio: Donde se carga el archivo y se muestra el logo.

Vista Director: An√°lisis global de todas las hojas del Excel.

Vista Docente: An√°lisis filtrado por una hoja espec√≠fica (aula o trimestre).

An√°lisis Estudiantil: Observaciones detalladas por alumno.

Exportar Reportes: Para descargar los datos procesados.

Ayuda y Referencias: Donde inclu√≠ la informaci√≥n del colegio y los enlaces del MINEDU.

Requisitos Implementados (Parte por Parte)

Logo del Colegio (P√°gina de Inicio):

He a√±adido el logo del "IE Victor Andres Belaunde" en la barra lateral. Por ahora, es un logo gen√©rico; deber√°s reemplazar la URL por la imagen oficial de tu colegio.

Carga de M√∫ltiples Hojas de Excel:

La funci√≥n cargar_excel ahora lee todas las hojas de tu archivo Excel y las almacena en un diccionario. Esto es la base para las vistas de Director y Docente.

Vista Director (Nueva P√°gina):

Esta p√°gina combina los datos de todas las hojas del Excel para dar una visi√≥n general.

Muestra KPIs (indicadores clave) como "Total de Estudiantes", "Promedio General" y "Tasa de Aprobaci√≥n" de todo el colegio.

Vista Docente (Nueva P√°gina):

¬°Esta es la funci√≥n clave que pediste! En esta p√°gina, el docente ve un men√∫ desplegable (st.selectbox).

Este men√∫ le permite elegir qu√© hoja de Excel (que representa un aula o trimestre) desea analizar.

Todos los gr√°ficos y m√©tricas en esta p√°gina se actualizan para mostrar solo los datos de la hoja seleccionada.

Escala de Notas (C=0-10, B=11-14...):

He implementado tu escala de calificaci√≥n exacta. Cre√© un diccionario llamado ESCALA_CALIFICACIONES al inicio del script que define estos rangos.

Todas las funciones que convierten de n√∫mero a letra (como convertir_promedio_a_letra) usan esta nueva escala.

Observaciones Mejoradas (P√°gina "An√°lisis Estudiantil"):

Cre√© la funci√≥n generar_observacion_mejorada.

Esta funci√≥n toma el promedio del estudiante, usa la nueva ESCALA_CALIFICACIONES para asignarle una letra (C, B, A, AD) y luego le da una estrategia de reforzamiento basada en el contexto del MINEDU y la informaci√≥n que me diste.

Esto hace que las observaciones sean mucho m√°s personalizadas y √∫tiles que un simple "aprobado".

Exportar Reportes (Nueva P√°gina):

Esta p√°gina cumple tu requisito de "producir y obtener esos Excel de forma personalizada".

El usuario (docente o director) puede seleccionar una hoja, y la aplicaci√≥n genera un reporte procesado (con promedios, observaciones, etc.) y ofrece un bot√≥n (st.download_button) para descargarlo como un archivo CSV o Excel.

P√°gina de Ayuda y Referencias (Nueva P√°gina):

Aqu√≠ he incluido todos los enlaces del MINEDU y gob.pe que me proporcionaste.

Tambi√©n a√±ad√≠ la informaci√≥n espec√≠fica del colegio (IE 40079 VICTOR NU√ëEZ VALENCIA, 26 alumnos/aula, etc.) como un FAQ, cumpliendo tu requisito de "resolver otras dudas".

2. Mejoras en cuaderno_mejorado.ipynb (El Notebook)

El cuaderno de Jupyter era un "starter" que usaba una configuraci√≥n gen√©rica. Lo he adaptado para que sea una herramienta de an√°lisis y modelado que refleje tus necesidades espec√≠ficas.

¬°El Cambio M√°s Importante! (Celda 5):

He actualizado el profiles_yaml. Tu escala de notas (C=0-10, B=11-14, A=15-17, AD=18-20) es diferente de la que tra√≠a el cuaderno (que usaba B=11-13).

He modificado el perfil MINEDU_NUEVO_2024 en el YAML para que los ranges_numeric_to_letter coincidan exactamente con los que me pediste. Esto es fundamental para que el modelo se entrene con las reglas correctas.

Funci√≥n de Observaci√≥n Mejorada (Nueva Celda):

He a√±adido la misma funci√≥n generar_observacion_mejorada que us√© en la app. Esto te permite probar y refinar la l√≥gica de las recomendaciones directamente en el notebook.

Manejo de M√∫ltiples Hojas (Nueva Celda):

He a√±adido una peque√±a celda que te muestra c√≥mo usar pd.ExcelFile para obtener los nombres de todas las hojas de tu archivo. Esto es clave para la "Vista Docente".

Modularidad y Nombres en Espa√±ol:

He renombrado algunas funciones (ej. limpiar_dataframe a limpiar_datos, generar_reporte_completo a generar_reporte_final) para que coincidan con la terminolog√≠a de tu app111.py y sea m√°s f√°cil migrar la l√≥gica del notebook a la aplicaci√≥n.


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Starter (Mejorado): Calificaciones en **letras** + CatBoost + Escala Personalizada\n",
    "\n",
    "Este cuaderno lee un Excel con **letras (AD/A/B/C)**, valida, y utiliza la **nueva escala de calificaci√≥n (C=0-10, B=11-14, etc.)**.\n",
    "\n",
    "Integra una **funci√≥n de observaci√≥n mejorada** basada en el contexto del MINEDU y entrena un `CatBoostClassifier` para generar un reporte predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si est√°s en un entorno limpio, descomenta e instala:\n",
    "# !pip install pandas catboost scikit-learn openpyxl pyyaml matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuraci√≥n: Perfil de Calificaci√≥n (ACTUALIZADO)\n",
    "\n",
    "**¬°IMPORTANTE!** Se ha actualizado `profiles_yaml` para usar la escala `MINEDU_NUEVO_2024`, que coincide con los rangos que solicitaste:\n",
    "\n",
    "* **C**: 0 - 10\n",
    "* **B**: 11 - 14\n",
    "* **A**: 15 - 17\n",
    "* **AD**: 18 - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil por defecto (puedes guardarlo/leerlo desde YAML externo)\n",
    "profiles_yaml = \"\"\"version: 2025-11-08 # Versi√≥n actualizada\n",
    "profiles:\n",
    "  MINEDU_NUEVO_2024:\n",
    "    letters_order: [AD, A, B, C]   # de mejor a peor\n",
    "    numeric_scale: 0..20\n",
    "    mapping_letter_to_numeric:     # representaci√≥n num√©rica \"representante\"\n",
    "      AD: 19\n",
    "      A:  16\n",
    "      B:  12\n",
    "      C:   8\n",
    "    ranges_numeric_to_letter:      # Escala EXACTA del usuario\n",
    "      AD: [18, 20]\n",
    "      A:  [15, 17]\n",
    "      B:  [11, 14]\n",
    "      C:  [0,  10]\n",
    "    pass_letters: [AD, A, B]       # letras consideradas \"Aprobado\"\n",
    "\"\"\"\n",
    "\n",
    "profiles = yaml.safe_load(profiles_yaml)\n",
    "PROFILE_NAME = \"MINEDU_NUEVO_2024\" # Usamos el nuevo perfil\n",
    "cfg = profiles[\"profiles\"][PROFILE_NAME]\n",
    "\n",
    "ESCALA_CALIFICACIONES = cfg[\"ranges_numeric_to_letter\"]\n",
    "MAPEO_LETRA_NUM = cfg[\"mapping_letter_to_numeric\"]\n",
    "LETRAS_APROBADAS = set(cfg[\"pass_letters\"])\n",
    "\n",
    "# Funciones de conversi√≥n basadas en el perfil cargado\n",
    "def convertir_letra_a_num(letter: str) -> float:\n",
    "    return MAPEO_LETRA_NUM.get(str(letter).strip().upper(), 8.0) # Default a 'C'\n",
    "\n",
    "def convertir_num_a_letra(value: float) -> str:\n",
    "    for letra, (lo, hi) in ESCALA_CALIFICACIONES.items():\n",
    "        if lo <= value <= hi:\n",
    "            return letra\n",
    "    return \"C\" # Default si est√° fuera de rango\n",
    "\n",
    "print(\"Perfil cargado:\", PROFILE_NAME, \"| Versi√≥n:\", profiles[\"version\"])\n",
    "print(\"Escala utilizada:\", ESCALA_CALIFICACIONES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Carga de datos (Manejo de M√∫ltiples Hojas)\n",
    "\n",
    "Actualizado para detectar y cargar todas las hojas de un archivo Excel, como se requiere para la \"Vista Docente\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâ Reemplaza esta ruta por tu archivo real\n",
    "ruta_archivo = Path(\"Nivel de logro - I Bimestre.xlsx\")\n",
    "\n",
    "def detectar_fila_encabezado(df_raw, palabras_clave=['APELLIDOS', 'NOMBRE', 'ESTUDIANTE']):\n",
    "    \"Detecta autom√°ticamente la fila que contiene el encabezado.\"\n",
    "    for i in range(min(10, len(df_raw))):\n",
    "        fila_str = ' '.join(str(x).upper() for x in df_raw.iloc[i] if pd.notna(x))\n",
    "        if any(clave in fila_str for clave in palabras_clave):\n",
    "            return i\n",
    "    return 0 # Default si no lo encuentra\n",
    "\n",
    "def cargar_excel(ruta_archivo: Path) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Carga todas las hojas de un archivo Excel en un diccionario.\"\"\"\n",
    "    try:\n",
    "        xls = pd.ExcelFile(ruta_archivo)\n",
    "        nombres_hojas = xls.sheet_names\n",
    "        print(f\"Hojas encontradas: {nombres_hojas}\")\n",
    "        \n",
    "        datos_por_hoja = {}\n",
    "        for hoja in nombres_hojas:\n",
    "            df_raw = pd.read_excel(xls, sheet_name=hoja, header=None)\n",
    "            fila_header = detectar_fila_encabezado(df_raw)\n",
    "            \n",
    "            df_hoja = pd.read_excel(xls, sheet_name=hoja, header=fila_header)\n",
    "            df_hoja = limpiar_datos(df_hoja)\n",
    "            if not df_hoja.empty:\n",
    "                datos_por_hoja[hoja] = df_hoja\n",
    "                print(f\"  ‚úì Hoja '{hoja}' cargada ({len(df_hoja)} filas)\")\n",
    "        \n",
    "        return datos_por_hoja\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar Excel: {e}\")\n",
    "        return {}\n",
    "\n",
    "def limpiar_datos(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"Limpia un DataFrame: elimina columnas/filas vac√≠as y normaliza nombres.\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values.tolist()] = [f\"{dup}.{i}\" if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed', na=False)]\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    if len(df.columns) > 1:\n",
    "        col_identificadora = df.columns[1]\n",
    "        df = df.dropna(subset=[col_identificadora])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Ejecuci√≥n de la carga\n",
    "datos_cargados = cargar_excel(ruta_archivo)\n",
    "\n",
    "# Para el an√°lisis del notebook, seleccionamos la primera hoja (o la que desees)\n",
    "if datos_cargados:\n",
    "    hoja_activa = list(datos_cargados.keys())[0]\n",
    "    df = datos_cargados[hoja_activa]\n",
    "    print(f\"\\nAnalizando hoja: '{hoja_activa}'\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Procesamiento y Creaci√≥n de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_columnas_notas(df):\n",
    "    \"Detecta columnas que probablemente sean notas (num√©ricas o A/B/C/AD).\"\n",
    "    columnas_notas = []\n",
    "    columnas_id = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_str = str(col).upper()\n",
    "        if any(kw in col_str for kw in ['ESTUDIANTE', 'NOMBRE', 'APELLIDO', 'GRADO', 'SECCION']):\n",
    "            columnas_id.append(col)\n",
    "            continue\n",
    "        if any(kw in col_str for kw in ['CODIGO', 'DNI', 'ID', 'PROMEDIO', 'OBSERVACION']):\n",
    "            continue\n",
    "        \n",
    "        muestra = df[col].dropna().sample(min(20, len(df[col].dropna())))\n",
    "        if muestra.empty:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            muestra_num = pd.to_numeric(muestra, errors='coerce').dropna()\n",
    "            if len(muestra_num) / len(muestra) > 0.8 and muestra_num.min() >= 0 and muestra_num.max() <= 20:\n",
    "                columnas_notas.append(col)\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            muestra_str = muestra.astype(str).str.upper().str.strip()\n",
    "            conteo_letras = muestra_str.isin(['A', 'B', 'C', 'AD']).sum()\n",
    "            if conteo_letras / len(muestra) > 0.7:\n",
    "                columnas_notas.append(col)\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "    return columnas_notas, columnas_id\n",
    "\n",
    "def procesar_datos_ml(df, columnas_notas):\n",
    "    \"Calcula promedios y convierte notas para el modelo.\"\n",
    "    df_proc = df.copy()\n",
    "    columnas_num_proc = []\n",
    "\n",
    "    for col in columnas_notas:\n",
    "        col_num_nombre = f\"{col}_num\"\n",
    "        columnas_num_proc.append(col_num_nombre)\n",
    "        \n",
    "        df_proc[col_num_nombre] = pd.to_numeric(df_proc[col], errors='coerce')\n",
    "        \n",
    "        df_proc[col_num_nombre] = df_proc[col_num_nombre].fillna(\n",
    "            df_proc[col].astype(str).str.upper().str.strip().map(MAPEO_LETRA_NUM)\n",
    "        )\n",
    "        \n",
    "        # Imputar NaN restantes con la nota de 'C'\n",
    "        df_proc[col_num_nombre] = df_proc[col_num_nombre].fillna(ESCALA_CALIFICACIONES['C']['num'])\n",
    "    \n",
    "    df_proc['PROMEDIO'] = df_proc[columnas_num_proc].mean(axis=1).round(2)\n",
    "    df_proc['CALIFICACION_LETRA'] = df_proc['PROMEDIO'].apply(convertir_num_a_letra)\n",
    "    df_proc['APROBADO'] = df_proc['CALIFICACION_LETRA'].apply(lambda x: 1 if x in LETRAS_APROBADAS else 0)\n",
    "    \n",
    "    return df_proc, columnas_num_proc\n",
    "\n",
    "# Ejecuci√≥n del procesamiento\n",
    "columnas_notas_detectadas, columnas_id_detectadas = obtener_columnas_notas(df)\n",
    "df_procesado, columnas_numericas = procesar_datos_ml(df, columnas_notas_detectadas)\n",
    "\n",
    "print(f\"Columnas de ID detectadas: {columnas_id_detectadas}\")\n",
    "print(f\"Columnas de Notas detectadas: {len(columnas_notas_detectadas)}\")\n",
    "print(f\"Columnas num√©ricas creadas: {len(columnas_numericas)}\")\n",
    "print(\"\\nDistribuci√≥n de Aprobaci√≥n (seg√∫n nueva escala):\")\n",
    "print(df_procesado['APROBADO'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento del Modelo (CatBoost)\n",
    "\n",
    "Usamos las columnas num√©ricas (0-20) como features para predecir el estado de Aprobado/Desaprobado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_catboost(df_entrenamiento, features, target='APROBADO'):\n",
    "    \"Entrena un modelo CatBoost y devuelve el modelo y sus m√©tricas.\"\n",
    "    \n",
    "    if df_entrenamiento[target].nunique() < 2:\n",
    "        print(\"Error: El target tiene una sola clase. No se puede entrenar el modelo.\")\n",
    "        return None, {}\n",
    "    \n",
    "    X = df_entrenamiento[features]\n",
    "    y = df_entrenamiento[target]\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    modelo = CatBoostClassifier(iterations=100,\n",
    "                              learning_rate=0.1,\n",
    "                              depth=6,\n",
    "                              loss_function='Logloss',\n",
    "                              verbose=False,\n",
    "                              random_seed=42)\n",
    "    \n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metricas = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"reporte\": classification_report(y_test, y_pred),\n",
    "        \"matriz_confusion\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(\"--- Resultados del Modelo ---\")\n",
    "    print(f\"Accuracy: {metricas['accuracy']:.4f}\")\n",
    "    print(\"Reporte de Clasificaci√≥n:\\n\", metricas['reporte'])\n",
    "    print(\"Matriz de Confusi√≥n:\\n\", metricas['matriz_confusion'])\n",
    "    \n",
    "    return modelo, metricas\n",
    "\n",
    "# Ejecutar entrenamiento\n",
    "features_para_modelo = columnas_numericas\n",
    "modelo_entrenado, metricas_modelo = entrenar_modelo_catboost(df_procesado, features_para_modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Generaci√≥n de Observaciones Mejoradas (¬°NUEVO!)\n",
    "\n",
    "Esta secci√≥n genera el reporte final, incluyendo las nuevas observaciones pedag√≥gicas basadas en el contexto del MINEDU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de conocimiento para recomendaciones (basada en enlaces MINEDU)\n",
    "ESTRATEGIAS_MINEDU = {\n",
    "    \"C\": \"üö® **Reforzamiento Urgente**: Requiere un plan de tutor√≠a individualizado. Foco en competencias b√°sicas. (Ref: MINEDU PEI 2024). Contactar a padres de familia.\",\n",
    "    \"B\": \"‚ö†Ô∏è **Acompa√±amiento Requerido**: Estudiante 'En Proceso'. Necesita material did√°ctico complementario, fomentar trabajo colaborativo y seguimiento semanal. (Ref: MINEDU).\",\n",
    "    \"A\": \"‚úÖ **Logro Esperado**: Consolidar aprendizaje. Asignar proyectos de aplicaci√≥n pr√°ctica para afianzar competencias.\",\n",
    "    \"AD\": \"üåü **Logro Destacado**: Fomentar investigaci√≥n, mentor√≠a a compa√±eros y preparaci√≥n para olimpiadas acad√©micas. (Ref: PEI 40079).\"\n",
    "}\n",
    "\n",
    "def generar_observacion_mejorada(promedio, nombre_estudiante=\"el estudiante\"):\n",
    "    \"\"\"\n",
    "    Genera observaci√≥n pedag√≥gica usando la nueva escala y contexto MINEDU.\n",
    "    \"\"\"\n",
    "    letra = convertir_num_a_letra(promedio)\n",
    "    descripcion = ESCALA_CALIFICACIONES[letra].get('desc', letra) # 'desc' puede no estar, usamos la letra\n",
    "    estrategia = ESTRATEGIAS_MINEDU[letra]\n",
    "    \n",
    "    observacion = f\"**Estudiante:** {nombre_estudiante}\\n\"\n",
    "    observacion += f\"**Promedio:** {promedio:.2f} | **Nivel:** {letra} ({descripcion})\\n\"\n",
    "    observacion += f\"**Observaci√≥n Pedag√≥gica:**\\n{estrategia}\"\n",
    "    \n",
    "    return observacion\n",
    "\n",
    "def generar_reporte_final(df_proc, modelo, features):\n",
    "    \"\"\"Genera el DataFrame final con predicciones y observaciones.\"\"\"\n",
    "    \n",
    "    df_reporte = df_proc.copy()\n",
    "    \n",
    "    # Predicciones del modelo\n",
    "    if modelo:\n",
    "        df_reporte['PROB_APROBADO'] = modelo.predict_proba(df_proc[features])[:, 1]\n",
    "        df_reporte['PRED_APROBADO'] = modelo.predict(df_proc[features])\n",
    "    else:\n",
    "        df_reporte['PROB_APROBADO'] = df_reporte['APROBADO'] # Usar el real si el modelo fall√≥\n",
    "        df_reporte['PRED_APROBADO'] = df_reporte['APROBADO']\n",
    "    \n",
    "    # Columna de ID (asegurarse de que existe)\n",
    "    col_nombre = columnas_id_detectadas[0] if columnas_id_detectadas else df_reporte.columns[0]\n",
    "\n",
    "    # Observaciones mejoradas\n",
    "    df_reporte['OBSERVACION_MEJORADA'] = df_reporte.apply(\n",
    "        lambda row: generar_observacion_mejorada(row['PROMEDIO'], row[col_nombre]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df_reporte\n",
    "\n",
    "# Generar el reporte\n",
    "df_final_reporte = generar_reporte_final(df_procesado, modelo_entrenado, features_para_modelo)\n",
    "\n",
    "# Mostrar ejemplo de las observaciones\n",
    "print(\"--- Ejemplo de Reporte Final con Observaciones Mejoradas ---\")\n",
    "columnas_a_mostrar = [col_nombre, 'PROMEDIO', 'CALIFICACION_LETRA', 'APROBADO', 'PROB_APROBADO', 'OBSERVACION_MEJORADA']\n",
    "columnas_existentes = [col for col in columnas_a_mostrar if col in df_final_reporte.columns]\n",
    "\n",
    "print(df_final_reporte[columnas_existentes].head())\n",
    "\n",
    "# Ejemplo de una observaci√≥n espec√≠fica\n",
    "print(\"\\n--- Observaci√≥n de un estudiante ---\")\n",
    "print(df_final_reporte.iloc[0]['OBSERVACION_MEJORADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}